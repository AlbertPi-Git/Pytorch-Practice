{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device as GPU if available\n",
    "useCuda=torch.cuda.is_available()\n",
    "device=torch.device('cuda:0' if useCuda else 'cpu')\n",
    "torch.backends.cudnn.benchmark=True     # If input images have the same size, enable benchmark can improve runtime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all params\n",
    "\n",
    "trainEpochs=5\n",
    "learningRate=1e-3\n",
    "\n",
    "# trainset loader params\n",
    "trainLoadParams = { 'batch_size': 32,\n",
    "                    'shuffle': True,\n",
    "                    'num_workers':8}\n",
    "# testset loader params\n",
    "testLoadParams = { 'batch_size': 64,\n",
    "                    'shuffle': True,\n",
    "                    'num_workers':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation to transform PIL image to tensor\n",
    "transforms=transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Read trainset and load with dataloader\n",
    "trainSet=datasets.MNIST(root='./MNIST_Data',train=True,download=True,transform=transforms)\n",
    "trainLoader=torch.utils.data.DataLoader(dataset=trainSet,**trainLoadParams) # ** dic  is a syntax sugar for fitting function parameters with elements of a dic\n",
    "\n",
    "# Read testset and load with dataloader\n",
    "testSet=datasets.MNIST(root='./MNIST_Data',train=False,download=True,transform=transforms)\n",
    "testLoader=torch.utils.data.DataLoader(dataset=testSet,**testLoadParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fully connected network with three hidden layers as the model\n",
    "class FC_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FC_Net,self).__init__()\n",
    "        # Flatten the image to 1d tensor as input. For MNIST the image size is (28,28), so the input size is 28*28 \n",
    "        self.inputSize=28*28\n",
    "        # 10 Categories in MNIST, so output size is 10\n",
    "        self.outputSize=10\n",
    "        self.hiddenLayerSizes=[256,128,64]\n",
    "        self.model=nn.Sequential( nn.Linear(self.inputSize,self.hiddenLayerSizes[0]),\n",
    "                                                    nn.ReLU(),\n",
    "                                                    nn.Linear(self.hiddenLayerSizes[0],self.hiddenLayerSizes[1]),\n",
    "                                                    nn.ReLU(),\n",
    "                                                    nn.Linear(self.hiddenLayerSizes[1],self.hiddenLayerSizes[2]),\n",
    "                                                    nn.ReLU(),\n",
    "                                                    nn.Linear(self.hiddenLayerSizes[2],self.outputSize)\n",
    "                                                    )\n",
    "    \n",
    "    def forward(self,flatImg):\n",
    "        # flatImg is batchSize*inputSize tensor\n",
    "        # output is batchSize*outputSize tensor\n",
    "        # Notice that there isn't softmax layer at the end, so the values of dim1 of output is not  probabilities of each catogories yet\n",
    "        return self.model(flatImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the fully connected network model \n",
    "model=FC_Net().to(device)\n",
    "\n",
    "# Instantiate the optimizer with weights of the network and learning rate of the optimizer\n",
    "optimizer=optim.Adam(params=model.parameters(), lr=learningRate)\n",
    "\n",
    "# Specify the loss function as cross entropy which is often used for multiclass classification\n",
    "lossFunc=nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate tensorboard writer\n",
    "TBwriter=SummaryWriter('./runs/MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(trainEpochs):\n",
    "    # Accumulating loss of each epoch\n",
    "    epochLoss=0 \n",
    "    for batchIndex, (imgs, labels) in enumerate(trainLoader):\n",
    "        \n",
    "        # Move images and labels to GPU is there is one\n",
    "        imgs, labels=imgs.to(device),labels.to(device)\n",
    "        \n",
    "        # A single input  (i.e. a single image in the batch) of  fully connected net is 1d tensor \n",
    "        imgs=torch.flatten(imgs,start_dim=1)\n",
    "        \n",
    "        # Gradient of left nodes will accumulate, so before backward propagation in each iteration, we need to reset the gradient \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute the output\n",
    "        preds=model.forward(imgs)\n",
    "        \n",
    "        # probabilities of each class is not normalized in output, but CrossEntropyLoss will do that, it equals LogSoftmax + Negative Log Likelyhood Loss \n",
    "        loss=lossFunc(preds,labels)\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        epochLoss+=float(loss)\n",
    "        \n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights of network using gradients obtained in backward propagation\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Write the loss of each batch to tensorboard\n",
    "        TBwriter.add_scalar('Train Loss', float(loss), epoch*len(trainLoader)+batchIndex)\n",
    "    \n",
    "    print('Epoch %d, Average loss is: %f' %(epoch,epochLoss/(len(trainLoader))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate predictions and labels of all test batchs, so that we can use sklearn.metrics to compute precision, recall and fbeta score\n",
    "allPreds,allLabels=torch.LongTensor([]).to(device),torch.LongTensor([])\n",
    "\n",
    "# Testing Loop\n",
    "for batchIndex, (imgs, labels) in enumerate(testLoader):\n",
    "    \n",
    "    # Only need images to compute predictions, so no need to move labels to GPU\n",
    "    imgs=imgs.to(device)\n",
    "    imgs=torch.flatten(imgs,start_dim=1)\n",
    "    \n",
    "    # Testing doesn't need to compute gradient\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Computer predictions\n",
    "        preds=model.forward(imgs)\n",
    "        \n",
    "        # Normalize the probabilities of all categories with Softmax\n",
    "        # Shape of preds is batchSize*categoryNum, so softmax the dim1\n",
    "        preds=nn.functional.softmax(preds,dim=1)\n",
    "        \n",
    "        # Pick the category that has the max probability as the prediction\n",
    "        # Shape of preds is batchSize*categoryNum, so find max in dim1\n",
    "        top1Prob,top1Indice=torch.max(preds,dim=1)\n",
    "    \n",
    "    # Show the prediction result on one test batch if you want\n",
    "    ''' \n",
    "    if batchIndex==0:\n",
    "        for img,pred in zip(imgs,top1Indice):\n",
    "            plt.imshow(img.view(28,28).cpu().numpy().squeeze())\n",
    "            plt.title('prediction: %d' %pred)\n",
    "            plt.show()\n",
    "    '''\n",
    "    \n",
    "    # Concatenate current batch predictsions and labels with previous ones\n",
    "    allPreds=torch.cat((allPreds,top1Indice),dim=0)\n",
    "    allLabels=torch.cat((allLabels,labels),dim=0)\n",
    "\n",
    "\n",
    "allPreds=allPreds.cpu().numpy()\n",
    "allLabels=allLabels.numpy()\n",
    "precion,recall,fbetaScore,_=metrics.precision_recall_fscore_support(y_pred=allPreds,y_true=allLabels,beta=1,average='weighted')\n",
    "print(\"{:<25}{}\".format('Weighted precision is: ',precion))\n",
    "print(\"{:<25}{}\".format('Weighted recall is: ',recall))\n",
    "print(\"{:<25}{}\".format('Weighted fbeta score is: ',fbetaScore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
